{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Notebook will be tha base for all the YOLO training that Reetta does in the project.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 0\n",
    "    print(f\"Training on GPU\")\n",
    "else:\n",
    "    print(f\"Training on CPU\")\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Default values used for all YOLO trainings.\n",
    "\n",
    "These parameters should remain consistent across different training runs,\n",
    "unless the hardware or training context changes significantly.\n",
    "\"\"\"\n",
    "\n",
    "model = YOLO(\"yolo11l.pt\")  # pretrained YOLOv11L model\n",
    "\n",
    "default_args = {\n",
    "    \"data\": \"config/materials.yaml\",     # dataset configuration path\n",
    "    \"imgsz\": 640,                     # default input size for YOLO\n",
    "    \"batch\": 16,                      # maximum batch size (GPU memory limit)\n",
    "    \"device\": 0,                      # GPU device ID\n",
    "    \"cache\": \"ram\",                   # cache data in RAM for speed\n",
    "    \"workers\": 4,                     # parallel data loader workers\n",
    "    \"amp\": True,                      # automatic mixed precision (faster training)\n",
    "    \"close_mosaic\": 10,               # disable mosaic in last N epochs\n",
    "    \"save\": True,                     # save checkpoints and weights\n",
    "    \"val\": True,                      # enable validation after each epoch\n",
    "    \"plots\": True                     # save training/validation plots\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run-specific training parameters.\n",
    "\n",
    "These parameters can be adjusted per experiment to test different configurations,\n",
    "optimizers, learning rates, or other hyperparameters.\n",
    "\"\"\"\n",
    "\n",
    "results = model.train(\n",
    "    **default_args,\n",
    "    epochs=50,                        # number of training epochs\n",
    "    optimizer=\"AdamW\",                # optimizer: AdamW, Adam, or SGD\n",
    "    lr0=0.001,                        # initial learning rate\n",
    "    momentum=0.85,                     # used with optimizers like SGD or AdamW\n",
    "    weight_decay=0.0002,              # regularization to prevent overfitting\n",
    "    warmup_epochs=5.0,                # warm-up period for learning rate\n",
    "    project=\"material_koulutus\",         # output base folder\n",
    "    name=\"train_reetta_v8\"             # unique name for this training run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script reads YOLO training results from a CSV file and visualizes key evaluation metrics:\n",
    "- Training and validation losses\n",
    "- Precision and recall over epochs\n",
    "- mAP scores at IoU 0.5 and 0.5â€“0.95\n",
    "- F1 score per epoch (calculated)\n",
    "- Confusion matrix (final)\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "csv_path = \"material_koulutus/train_reetta_v4/results.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "display(df.head())\n",
    "display(df.tail())\n",
    "\n",
    "df[[\"train/box_loss\", \"train/cls_loss\", \"train/dfl_loss\"]].plot(figsize=(10, 5), title=\"Training Losses per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "df[[\"val/box_loss\", \"val/cls_loss\", \"val/dfl_loss\"]].plot(figsize=(10, 5), title=\"Validation Losses per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "df[[\"metrics/precision(B)\", \"metrics/recall(B)\"]].plot(figsize=(10, 5), title=\"Precision and Recall\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "df[[\"metrics/mAP50(B)\", \"metrics/mAP50-95(B)\"]].plot(figsize=(10, 5), title=\"mAP Scores\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "df[[\"lr/pg0\", \"lr/pg1\", \"lr/pg2\"]].plot(figsize=(10, 5), title=\"Learning Rates\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "if \"metrics/precision(B)\" in df.columns and \"metrics/recall(B)\" in df.columns:\n",
    "    precision = df[\"metrics/precision(B)\"]\n",
    "    recall = df[\"metrics/recall(B)\"]\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df[\"epoch\"], f1, label=\"F1 Score\")\n",
    "    plt.title(\"F1 Score per Epoch\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "cm_path = \"material_koulutus/train_reetta_v8/confusion_matrix.png\"\n",
    "if os.path.exists(cm_path):\n",
    "    img = Image.open(cm_path)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Confusion Matrix (Final Epoch)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
