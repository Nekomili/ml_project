{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"/home/jovyan/shared/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_table = \"training\"\n",
    "validation_table = \"validation\"\n",
    "\n",
    "with sqlite3.connect(\"../data/database/annotations.sqlite\") as conn:\n",
    "    training_df = pd.read_sql_query(f\"SELECT * FROM {training_table};\", conn)\n",
    "    validation_df = pd.read_sql_query(f\"SELECT * FROM {validation_table};\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_df)\n",
    "len(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"/home/jovyan/shared/dataset/\"\n",
    "\n",
    "output_dir = \"../YOLO/datasets/materials\"\n",
    "\n",
    "os.symlink(os.path.join(IMAGE_PATH, \"174110_1.jpg\"), os.path.join(output_dir, \"174110_1.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_training_files(training_df:pd.DataFrame, output_dir = \"../YOLO/datasets/materials\", img_path = \"/home/jovyan/shared/dataset/\"):\n",
    "    train_label_dir = os.path.join(output_dir, \"labels\", \"train\")\n",
    "    train_image_dir = os.path.join(output_dir, \"images\", \"train\")\n",
    "    if not os.path.exists(train_label_dir) or not os.path.exists(train_image_dir):\n",
    "        print(train_label_dir)\n",
    "        os.makedirs(train_label_dir)\n",
    "        os.makedirs(train_image_dir)\n",
    "    for filename, group_df in training_df.groupby('file'):\n",
    "        txt_filename = filename\n",
    "        txt_filepath = os.path.join(train_label_dir, txt_filename)\n",
    "        img_filename = filename.split('.')[0]+\".jpg\"\n",
    "        with open(txt_filepath, 'w', encoding='utf-8') as f:\n",
    "            for _, row in group_df.iterrows():\n",
    "                class_id = int(row['class'])\n",
    "                x_center = row['x-center']\n",
    "                y_center = row['y-center']\n",
    "                width = row['width']\n",
    "                height = row['height']\n",
    "\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "        os.symlink(os.path.join(img_path, img_filename), os.path.join(train_image_dir, img_filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_training_files(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_validation_data(validation_df:pd.DataFrame, output_dir = \"../YOLO/datasets/materials\", img_path = \"/home/jovyan/shared/dataset/\"):\n",
    "    validation_label_dir = os.path.join(output_dir, \"labels\", \"validation\")\n",
    "    validation_image_dir = os.path.join(output_dir, \"images\", \"validation\")\n",
    "    if not os.path.exists(validation_label_dir) or not os.path.exists(validation_image_dir):\n",
    "        print(validation_label_dir)\n",
    "        os.makedirs(validation_label_dir)\n",
    "        os.makedirs(validation_image_dir)\n",
    "    for filename, group_df in validation_df.groupby('file'):\n",
    "        txt_filename = filename\n",
    "        txt_filepath = os.path.join(validation_label_dir, txt_filename)\n",
    "        img_filename = filename.split('.')[0]+\".jpg\"\n",
    "        with open(txt_filepath, 'w', encoding='utf-8') as f:\n",
    "            for _, row in group_df.iterrows():\n",
    "                class_id = int(row['class'])\n",
    "                x_center = row['x-center']\n",
    "                y_center = row['y-center']\n",
    "                width = row['width']\n",
    "                height = row['height']\n",
    "\n",
    "                f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "        os.symlink(os.path.join(img_path, img_filename), os.path.join(validation_image_dir, img_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_validation_data(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
