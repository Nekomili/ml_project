{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# YOLO DenseNet Hybrid pipeline\n",
    "## hybrid_pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import logging\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "# Logging config\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(\"HybridPipeline\")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Train YOLO model\n",
    "\n",
    "TÃ¤tÃ¤ ei tehdÃ¤ vaan ladataan mika_best malli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def train_yolo():\n",
    "    print(\"\\nðŸ”§ Koulutetaan YOLO-mallia...\")\n",
    "    model = YOLO('yolo11s.pt')\n",
    "    model.train(\n",
    "        data='config/materials.yaml',\n",
    "        epochs=40,\n",
    "        imgsz=768,\n",
    "        batch=16,\n",
    "        patience=20,\n",
    "        cache=False,\n",
    "        project='runs/train',\n",
    "        name='materials_test_direct',\n",
    "        exist_ok=True,\n",
    "        lr0=0.003,\n",
    "        momentum=0.937,\n",
    "        weight_decay=0.0001,\n",
    "        warmup_epochs=5.0,\n",
    "        warmup_momentum=0.8,\n",
    "        box=0.05,\n",
    "        cls=0.5,\n",
    "        dfl=1.5,\n",
    "        hsv_h=0.015,\n",
    "        hsv_s=0.7,\n",
    "        hsv_v=0.4,\n",
    "        translate=0.1,\n",
    "        scale=0.8,\n",
    "        perspective=0.002,\n",
    "        fliplr=0.5,\n",
    "        mosaic=0.2,\n",
    "        mixup=0.1,\n",
    "        copy_paste=0.05\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"âœ… YOLO-koulutus valmis.\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Validate YOLO model\n",
    "\n",
    "mika_best validointi. Klikkaa pois, jos ei tarvetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_yolo():\n",
    "    print(\"\\nðŸ” Validoidaan YOLO-malli...\")\n",
    "    model = YOLO('paras_yolo_malli/mika_best.pt') \n",
    "    results = model.val(augment=True)\n",
    "\n",
    "    print(f\"\\nmAP@0.5: {results.box.map50:.4f}\")\n",
    "    print(f\"mAP@0.5:0.95: {results.box.map:.4f}\\n\")\n",
    "\n",
    "    ap_list = results.box.ap\n",
    "    p_list = results.box.p\n",
    "    r_list = results.box.r\n",
    "    class_names = list(results.names.values())\n",
    "\n",
    "    for i in range(len(ap_list)):\n",
    "        print(f\"Class '{class_names[i]}': Precision = {p_list[i]:.4f}, Recall = {r_list[i]:.4f}, AP = {ap_list[i]:.4f}\")\n",
    "\n",
    "    print(\"âœ… YOLO-validointi valmis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Generate cropped images\n",
    "\n",
    "kuvien croppaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cropped_images(image_root, label_root, output_root):\n",
    "    print(f\"\\nâœ‚ï¸  Rajataan kuvia hakemistoista: {image_root} â†’ {output_root}\")\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    image_paths = sorted(glob.glob(os.path.join(image_root, '*.jpg')) + glob.glob(os.path.join(image_root, '*.png')))\n",
    "    for img_path in image_paths:\n",
    "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(label_root, f\"{name}.txt\")\n",
    "        if not os.path.exists(label_path): continue\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        h, w = img.shape[:2]\n",
    "        with open(label_path, 'r') as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                class_id, xc, yc, bw, bh = map(float, line.strip().split())\n",
    "                x1 = max(0, int((xc - bw / 2) * w))\n",
    "                y1 = max(0, int((yc - bh / 2) * h))\n",
    "                x2 = min(w, int((xc + bw / 2) * w))\n",
    "                y2 = min(h, int((yc + bh / 2) * h))\n",
    "                cropped = img[y1:y2, x1:x2]\n",
    "                if cropped.size == 0: continue\n",
    "                out_path = os.path.join(output_root, str(int(class_id)), f\"{name}_{idx}.jpg\")\n",
    "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "                cv2.imwrite(out_path, cropped)\n",
    "    print(\"âœ… Kuvien rajaaminen valmis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Train DenseNet\n",
    "\n",
    "Tallentaa tuloksen \"densenet_materials_best.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_densenet():\n",
    "    print(\"\\nðŸ‹ï¸â€â™‚ï¸ Koulutetaan DenseNet-malli...\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_data = datasets.ImageFolder('datasets/materials/cropped/train', transform=transform)\n",
    "    val_data = datasets.ImageFolder('datasets/materials/cropped/validation', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, len(train_data.classes))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    train_losses, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(25):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1:02d}: Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'densenet_materials_best.pth')\n",
    "\n",
    "    print(\"âœ… DenseNet-koulutus valmis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Evaluate Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_densenet():\n",
    "    print(\"\\nðŸ” Arvioidaan DenseNet-mallia validointidatalla...\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    val_data = datasets.ImageFolder('datasets/materials/cropped/validation', transform=transform)\n",
    "    val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = models.densenet121(weights=None)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, len(val_data.classes))\n",
    "    model.load_state_dict(torch.load(\"densenet_materials_best.pth\", map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(\"\\nâœ… DenseNet tarkkuusvalidaatio:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=val_data.classes, zero_division=0))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Evaluate hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid():\n",
    "    print(\"\\nðŸ” Arvioidaan hybridimallia...\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    class_names = datasets.ImageFolder(\"datasets/materials/cropped/train\", transform=transform).classes\n",
    "    densenet_model = models.densenet121(weights=None)\n",
    "    densenet_model.classifier = nn.Linear(densenet_model.classifier.in_features, len(class_names))\n",
    "    densenet_model.load_state_dict(torch.load(\"densenet_materials_best.pth\", map_location=device))\n",
    "    densenet_model.to(device)\n",
    "    densenet_model.eval()\n",
    "\n",
    "    yolo_model = YOLO(\"paras_yolo_malli/mika_best.pt\")\n",
    "\n",
    "    image_paths = glob.glob(\"datasets/materials/images/validation/*.jpg\") + \\\n",
    "                  glob.glob(\"datasets/materials/images/validation/*.png\")\n",
    "\n",
    "    results_counter = Counter()\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        results = yolo_model(img_path)[0]\n",
    "        for box in results.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            yolo_cls = int(box.cls[0])\n",
    "            yolo_conf = float(box.conf[0])\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            if crop.shape[0] == 0 or crop.shape[1] == 0:\n",
    "                continue\n",
    "            pil_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "            input_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                output = densenet_model(input_tensor)\n",
    "                densenet_cls = output.argmax(dim=1).item()\n",
    "                densenet_conf = torch.softmax(output, dim=1)[0][densenet_cls].item()\n",
    "\n",
    "            if yolo_conf >= 0.75:\n",
    "                final_cls = yolo_cls\n",
    "                source = \"YOLO\"\n",
    "            else:\n",
    "                final_cls = densenet_cls\n",
    "                source = \"DenseNet\"\n",
    "\n",
    "            results_counter[(class_names[final_cls], source)] += 1\n",
    "\n",
    "    print(\"\\nðŸ“Š Hybridiluokituksen tulokset:\")\n",
    "    for (cls_name, source), count in sorted(results_counter.items()):\n",
    "        print(f\"{cls_name:25s} [{source}]: {count} kpl\")\n",
    "    print(\"âœ… Hybridimallin arviointi valmis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_examples():\n",
    "    print(\"\\nðŸŽ² Ajetaan 3 satunnaista esimerkkikuvaa hybridimallilla...\")\n",
    "    all_images = glob.glob(\"datasets/materials/images/validation/*.jpg\") + \\\n",
    "                 glob.glob(\"datasets/materials/images/validation/*.png\")\n",
    "    used_images = [\"datasets/materials/images/validation/174114_2.jpg\"]\n",
    "    remaining_images = list(set(all_images) - set(used_images))\n",
    "    random_images = random.sample(remaining_images, 3)\n",
    "    for path in random_images:\n",
    "        show_yolo_vs_densenet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        return shell == 'ZMQInteractiveShell'\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if in_notebook():\n",
    "        print(\"ðŸ“˜ Ajetaan Jupyterissa â€“ ohitetaan komentoriviargumentit.\")\n",
    "    else:\n",
    "        import argparse\n",
    "\n",
    "        parser = argparse.ArgumentParser(description=\"YOLO + DenseNet hybrid pipeline\")\n",
    "        #parser.add_argument('--train_yolo', action='store_true', help='Train YOLO model')\n",
    "        parser.add_argument('--validate_yolo', action='store_true', help='Validate YOLO model')\n",
    "        parser.add_argument('--generate_crops', action='store_true', help='Generate cropped images from YOLO labels')\n",
    "        parser.add_argument('--train_densenet', action='store_true', help='Train DenseNet model')\n",
    "        parser.add_argument('--evaluate_hybrid', action='store_true', help='Evaluate hybrid YOLO + DenseNet model')\n",
    "        parser.add_argument('--evaluate_densenet', action='store_true', help='Evaluate DenseNet model performance on validation set')\n",
    "print(type(batch))\n",
    "        args = parser.parse_args()\n",
    "\n",
    "        #if args.train_yolo:\n",
    "        #    train_yolo()\n",
    "\n",
    "        if args.validate_yolo:\n",
    "            validate_yolo()\n",
    "\n",
    "        if args.generate_crops:\n",
    "            generate_cropped_images('datasets/materials/images/train', 'datasets/materials/labels/train', 'datasets/materials/cropped/train')\n",
    "            generate_cropped_images('datasets/materials/images/validation', 'datasets/materials/labels/validation', 'datasets/materials/cropped/validation')\n",
    "\n",
    "        if args.train_densenet:\n",
    "            train_densenet()\n",
    "\n",
    "        if args.evaluate_hybrid:\n",
    "            evaluate_hybrid()\n",
    "\n",
    "        if args.evaluate_densenet:\n",
    "            evaluate_densenet()\n",
    "\n",
    "        if args.show_examples:\n",
    "            run_random_examples()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(directory):\n",
    "  try:\n",
    "    filenames = os.listdir(directory)\n",
    "    return filenames\n",
    "  except FileNotFoundError:\n",
    "    return []\n",
    "\n",
    "def compare_dense_models():\n",
    "    models = list_files(\"./paras_dense_malli\")\n",
    "    for model in models:\n",
    "        evaluate_chosen_densenet(model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 7. Kutsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#train_yolo()\n",
    "validate_yolo()\n",
    "generate_cropped_images('datasets/materials/images/train', 'datasets/materials/labels/train', 'datasets/materials/cropped/train')\n",
    "generate_cropped_images('datasets/materials/images/validation', 'datasets/materials/labels/validation', 'datasets/materials/cropped/validation')\n",
    "train_densenet()\n",
    "evaluate_densenet()\n",
    "evaluate_hybrid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chosen_densenet(model_name, model_architecture=None):\n",
    "    print(f\"\\nðŸ” Arvioidaan DenseNet-mallia {model_name} validointidatalla...\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    val_data = datasets.ImageFolder('datasets/materials/cropped/validation', transform=transform)\n",
    "    val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "    if \"d169\" in model_name:\n",
    "        model = models.densenet169(weights=None)\n",
    "    else:\n",
    "        model = models.densenet121(weights=None)\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, len(val_data.classes))\n",
    "    model.load_state_dict(torch.load(f\"./paras_dense_malli/{model_name}\", map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    print(\"\\nâœ… DenseNet tarkkuusvalidaatio:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=val_data.classes, zero_division=0))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_cropped_images('datasets/materials/images/validation', 'datasets/materials/labels/validation', 'datasets/materials/cropped/validation')\n",
    "compare_dense_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_yolo_vs_densenet(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    class_names = datasets.ImageFolder(\"datasets/materials/cropped/train\", transform=transform).classes\n",
    "\n",
    "    yolo_model = YOLO(\"paras_yolo_malli/mika_best.pt\")\n",
    "    densenet_model = models.densenet121(weights=None)\n",
    "    densenet_model.classifier = nn.Linear(densenet_model.classifier.in_features, len(class_names))\n",
    "    densenet_model.load_state_dict(torch.load(\"densenet_materials_best.pth\", map_location=device))\n",
    "    densenet_model.to(device)\n",
    "    densenet_model.eval()\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = img.shape[:2]\n",
    "    yolo_img, densenet_img, hybrid_img = img.copy(), img.copy(), img.copy()\n",
    "\n",
    "    results = yolo_model.predict(image_path, verbose=False)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        yolo_cls = int(box.cls[0])\n",
    "        yolo_conf = float(box.conf[0])\n",
    "        label = f\"{class_names[yolo_cls]} ({yolo_conf*100:.1f}%)\"\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale, thickness = 1.5, 4\n",
    "        (text_w, text_h), _ = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "        text_x = x1 + (x2 - x1 - text_w) // 2\n",
    "        text_y = max(y1 - 10, text_h + 10)\n",
    "\n",
    "        cv2.rectangle(yolo_img, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "        cv2.putText(yolo_img, label, (text_x, text_y), font, font_scale, (0, 255, 255), thickness)\n",
    "\n",
    "        crop = densenet_img[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "        input_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = densenet_model(input_tensor)\n",
    "            pred_cls = output.argmax(dim=1).item()\n",
    "            dn_conf = torch.softmax(output, dim=1)[0][pred_cls].item()\n",
    "\n",
    "        dn_label = f\"{class_names[pred_cls]} ({dn_conf*100:.1f}%)\"\n",
    "        cv2.rectangle(densenet_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(densenet_img, dn_label, (text_x, text_y), font, font_scale, (0, 255, 0), thickness)\n",
    "\n",
    "        if yolo_conf >= 0.75:\n",
    "            final_cls, final_conf, source, color = yolo_cls, yolo_conf, \"YOLO\", (0, 255, 255)\n",
    "        else:\n",
    "            final_cls, final_conf, source, color = pred_cls, dn_conf, \"DenseNet\", (0, 255, 0)\n",
    "\n",
    "        hybrid_label = f\"{class_names[final_cls]} ({final_conf*100:.1f}%) [{source}]\"\n",
    "        cv2.rectangle(hybrid_img, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(hybrid_img, hybrid_label, (text_x, text_y), font, font_scale, color, thickness)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(yolo_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"YOLO-luokitus\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(densenet_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"DenseNet-luokitus\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cv2.cvtColor(hybrid_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Hybridiluokitus\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nðŸ“˜ Luokkakoodien selitykset:\")\n",
    "    for idx, name in enumerate(class_names):\n",
    "        print(f\"{idx} = {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_yolo_vs_densenet(\"datasets/materials/images/validation/176137_1.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poistaa jo kÃ¤ytetyt ja valitsee kolme uutta kuvaa\n",
    "run_random_examples()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## TÃ¤mÃ¤ on itse kuvattu ja ladattu kuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_yolo_vs_densenet(\"datasets/materials/images/testikuva.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
