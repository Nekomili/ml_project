{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### ðŸ”§ Alustukset ja asetukset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from ultralytics.utils import LOGGER\n",
    "import logging\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### ðŸ§  YOLO-mallin koulutus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LOGGER.setLevel(logging.ERROR)\n",
    "\n",
    "# ðŸ“¦ Lataa malli\n",
    "model = YOLO('yolo11x.pt')\n",
    "model.to(device)\n",
    "\n",
    "# ðŸ§ª Kouluta malli suoraan parametreilla (ei cfg)\n",
    "model.train(\n",
    "    data='config/materials.yaml',\n",
    "    epochs=30,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    patience=10,\n",
    "    cache=False, \n",
    "    project='runs/train',\n",
    "    name='materials_test_direct',\n",
    "    exist_ok=True,\n",
    "    lr0=0.005,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3.0,\n",
    "    warmup_momentum=0.8,\n",
    "    box=0.03,\n",
    "    cls=0.4,\n",
    "    dfl=1.5,\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=0.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    shear=1-2,\n",
    "    perspective=0.002,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=0.1,\n",
    "    mixup=0.1,\n",
    "    copy_paste=0.0\n",
    ")\n",
    "\n",
    "# ðŸ§¹ TyhjennÃ¤ mahdollinen ylimÃ¤Ã¤rÃ¤inen muisti\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ðŸ” Validoi malli\n",
    "model = YOLO('runs/train/materials_test_direct/weights/best.pt')\n",
    "model.to(device)\n",
    "results = model.val(augment=True) #Test Time Augmentation\n",
    "\n",
    "# ðŸ§¹ TyhjennÃ¤ mahdollinen ylimÃ¤Ã¤rÃ¤inen muisti\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ðŸ§¾ Kokonaistulokset\n",
    "print(\"\\nâœ… YOLO-validointi:\")\n",
    "print(f\"mAP@0.5:      {results.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {results.box.map:.4f}\\n\")\n",
    "\n",
    "# ðŸ” Luokkakohtaiset mittarit\n",
    "ap_list = results.box.ap\n",
    "precisions = results.box.p\n",
    "recalls = results.box.r\n",
    "class_names = list(results.names.values())\n",
    "\n",
    "print(\"ðŸ“Š Luokkakohtaiset tulokset:\\n\")\n",
    "for i, class_id in enumerate(list(results.names.keys())[:len(ap_list)]):\n",
    "    name = results.names[class_id]\n",
    "    print(f\"Class '{name:20s}': Precision = {precisions[i]:.4f}, Recall = {recalls[i]:.4f}, AP = {ap_list[i]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Confusion matrix \n",
    "if hasattr(results, \"confusion_matrix\"):\n",
    "    cm = results.confusion_matrix.matrix\n",
    "    class_names = list(results.names.values())\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".0f\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"YOLO Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Confusion matrix ei ole saatavilla.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### âœ… Tarkista validointikuvien labelit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'datasets/materials/images/validation'\n",
    "label_dir = 'datasets/materials/labels/validation'\n",
    "\n",
    "image_files = sorted(glob.glob(f'{image_dir}/*.jpg')) + sorted(glob.glob(f'{image_dir}/*.png'))\n",
    "missing_labels = [os.path.basename(f) for f in image_files\n",
    "                  if not os.path.exists(os.path.join(label_dir, os.path.splitext(os.path.basename(f))[0] + '.txt'))]\n",
    "\n",
    "if missing_labels:\n",
    "    print(\"âš ï¸ NÃ¤iltÃ¤ kuvilta puuttuu label:\")\n",
    "    for f in missing_labels:\n",
    "        print(\"-\", f)\n",
    "else:\n",
    "    print(\"âœ… Kaikille kuville lÃ¶ytyy labelit.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### ðŸ” Ennusteet validointikuville + visualisointi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = YOLO('runs/train/materials_test_direct/weights/best.pt')\n",
    "results = trained_model(image_files[:6])\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))  # 2 riviÃ¤, 3 saraketta\n",
    "axes = axes.flatten()  # helpottaa indeksin kÃ¤yttÃ¶Ã¤\n",
    "\n",
    "for i, r in enumerate(results):\n",
    "    img_rgb = cv2.cvtColor(r.plot(), cv2.COLOR_BGR2RGB)\n",
    "    axes[i].imshow(img_rgb)\n",
    "    axes[i].set_title(os.path.basename(image_files[i]))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# Jos vÃ¤hemmÃ¤n kuvia kuin paikkoja (varmuuden vuoksi)\n",
    "for j in range(len(results), len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### âœ‚ï¸ Croppaa kuvat YOLO-labelien mukaan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cropped_images(image_root, label_root, output_root):\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    image_paths = sorted(glob.glob(os.path.join(image_root, '*.jpg'))) + \\\n",
    "                  sorted(glob.glob(os.path.join(image_root, '*.png')))\n",
    "    for img_path in image_paths:\n",
    "        name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        label_path = os.path.join(label_root, f\"{name}.txt\")\n",
    "        if not os.path.exists(label_path): continue\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: continue\n",
    "        h, w = img.shape[:2]\n",
    "        with open(label_path, 'r') as f:\n",
    "            for idx, line in enumerate(f):\n",
    "                class_id, xc, yc, bw, bh = map(float, line.strip().split())\n",
    "                x1 = max(0, int((xc - bw / 2) * w))\n",
    "                y1 = max(0, int((yc - bh / 2) * h))\n",
    "                x2 = min(w, int((xc + bw / 2) * w))\n",
    "                y2 = min(h, int((yc + bh / 2) * h))\n",
    "                cropped = img[y1:y2, x1:x2]\n",
    "                if cropped.size == 0: continue\n",
    "                out_path = os.path.join(output_root, str(int(class_id)), f\"{name}_{idx}.jpg\")\n",
    "                os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "                cv2.imwrite(out_path, cropped)\n",
    "\n",
    "for split in ['train', 'validation']:\n",
    "    generate_cropped_images(f'datasets/materials/images/{split}', f'datasets/materials/labels/{split}', f'datasets/materials/cropped/{split}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### ðŸ‹ï¸ DenseNet-koulutus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ðŸ”„ Transformit\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ðŸ“‚ Datasetit ja DataLoaderit\n",
    "train_data = datasets.ImageFolder('datasets/materials/cropped/train', transform=transform)\n",
    "val_data = datasets.ImageFolder('datasets/materials/cropped/validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# ðŸ§  Malli: DenseNet121 esikoulutettuna\n",
    "model = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, len(train_data.classes))\n",
    "model = model.to(device)\n",
    "\n",
    "# âš™ï¸ Koulutuksen asetukset\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# ðŸ“Š Koulutushistorian seurantamuuttujat\n",
    "train_losses, val_accuracies = [], []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# ðŸ‹ï¸â€â™‚ï¸ Koulutussilmukka\n",
    "for epoch in range(25):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # ðŸ” Validointi\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Acc = {train_acc:.2f}%, Val Acc = {val_acc:.2f}%\")\n",
    "\n",
    "    # ðŸ’¾ Tallenna paras malli\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'densenet_materials_best.pth')\n",
    "\n",
    "# ðŸ“ˆ Visualisointi: Loss ja Accuracy\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ðŸŽ¯ Validation Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, val_accuracies, marker='o', label='Val Accuracy', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Validation Accuracy over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# ðŸ“‰ Training Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_losses, marker='o', label='Train Loss', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### ðŸ¤– Hybridiluokitus validointikuville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_names = train_data.classes\n",
    "yolo_model = YOLO('runs/train/materials_test_direct/weights/best.pt')\n",
    "model.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "validation_images = glob.glob('datasets/materials/images/validation/*.jpg') + \\\n",
    "                    glob.glob('datasets/materials/images/validation/*.png')\n",
    "\n",
    "results_counter = Counter()\n",
    "\n",
    "for img_path in validation_images:\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    results = yolo_model(img_path)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        yolo_cls = int(box.cls[0])\n",
    "        yolo_conf = float(box.conf[0])\n",
    "\n",
    "        crop = img[y1:y2, x1:x2]\n",
    "        if crop.shape[0] == 0 or crop.shape[1] == 0: # korvattu crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "        input_tensor = preprocess(pil_img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            densenet_cls = output.argmax(dim=1).item()\n",
    "            densenet_conf = torch.softmax(output, dim=1)[0][densenet_cls].item()\n",
    "\n",
    "        # Valitaan YOLO tai DenseNet\n",
    "        if yolo_conf >= 0.75:\n",
    "            final_cls = yolo_cls\n",
    "            source = \"YOLO\"\n",
    "        else:\n",
    "            final_cls = densenet_cls\n",
    "            source = \"DenseNet\"\n",
    "\n",
    "        results_counter[(class_names[final_cls], source)] += 1\n",
    "\n",
    "# ðŸ§¾ Tulosta yhteenveto\n",
    "print(\"\\nðŸ” Luokitusyhteenveto (hybridimalli, valinta YOLO vs DenseNet):\\n\")\n",
    "for (cls_name, source), count in sorted(results_counter.items()):\n",
    "    print(f\"{cls_name:25s} [{source}]: {count} kpl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### ðŸ“Š DenseNetin suorituskykymittarit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = datasets.ImageFolder('datasets/materials/cropped/validation', transform=transform)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "print(\"\\nâœ… DenseNet tarkkuusvalidaatio:\")\n",
    "print(classification_report(y_true, y_pred, target_names=val_data.classes, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## ðŸ§  **Vertailufunktio**\n",
    "\n",
    "- Lataa yhden kuvan polusta image_path\n",
    "- KÃ¤yttÃ¤Ã¤ YOLO-mallia havaitakseen kohteet ja piirtÃ¤Ã¤ ne kuvaan\n",
    "\n",
    "Jokaisen havaintoboksin kohdalla:\n",
    "- YOLO antaa luokan ja todennÃ¤kÃ¶isyyden â†’ piirretÃ¤Ã¤n keltaisella\n",
    "- DenseNet luokittelee saman alueen â†’ piirretÃ¤Ã¤n vihreÃ¤llÃ¤\n",
    "- HybridisÃ¤Ã¤ntÃ¶: jos YOLO:n varmuus â‰¥ 75 %, kÃ¤ytetÃ¤Ã¤n YOLOa, muuten DenseNetiÃ¤ â†’ piirretÃ¤Ã¤n laatikko ja label, jossa nÃ¤kyy kumpaa mallia kÃ¤ytettiin\n",
    "\n",
    "Tarkkuudet (%) nÃ¤ytetÃ¤Ã¤n laatikon ylÃ¤puolella\n",
    "\n",
    "NÃ¤yttÃ¤Ã¤ kolme kuvaa rinnakkain:\n",
    "- YOLO-tulokset\n",
    "- DenseNet-tulokset\n",
    "- Hybridimallin tulokset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_yolo_vs_densenet(image_path):\n",
    "\n",
    "    \n",
    "    # Asetukset\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "\n",
    "    # Luokat\n",
    "    sample_dataset = datasets.ImageFolder(\"datasets/materials/cropped/train\", transform=transform)\n",
    "    class_names = sample_dataset.classes\n",
    "\n",
    "    # Mallit\n",
    "    yolo_model = YOLO(\"runs/train/materials_test_direct/weights/best.pt\")\n",
    "    densenet_model = models.densenet121(weights=None)\n",
    "    densenet_model.classifier = torch.nn.Linear(densenet_model.classifier.in_features, len(class_names))\n",
    "    densenet_model.load_state_dict(torch.load(\"densenet_materials_5class.pth\", map_location=device))\n",
    "    densenet_model.to(device)\n",
    "    densenet_model.eval()\n",
    "\n",
    "    # Kuva\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Valmistele kopiot\n",
    "    yolo_img = img.copy()\n",
    "    densenet_img = img.copy()\n",
    "    hybrid_img = img.copy()\n",
    "\n",
    "    # YOLO ennusteet\n",
    "    #results = yolo_model(image_path)[0] piirtÃ¤Ã¤ kaikki ennustetut ja tallennetut bounding boxit\n",
    "    results = yolo_model.predict(image_path, verbose=False)[0] # kÃ¤ynnistÃ¤Ã¤ uuden puhtaan ennusteen ja verbose=False estÃ¤Ã¤ turhan tulostamisen.\n",
    "\n",
    "\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "        # YOLO\n",
    "        yolo_cls = int(box.cls[0])\n",
    "        yolo_conf = float(box.conf[0])\n",
    "        yolo_label = f\"{class_names[yolo_cls]} ({yolo_conf*100:.1f}%)\"\n",
    "        cv2.rectangle(yolo_img, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "        # Labelin mÃ¤Ã¤rittely\n",
    "        label = f\"{class_names[yolo_cls]} ({yolo_conf*100:.1f}%)\"\n",
    "        \n",
    "        # Tekstin koko ja sijainti\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 1.5\n",
    "        thickness = 4\n",
    "        (text_w, text_h), _ = cv2.getTextSize(label, font, font_scale, thickness)\n",
    "        text_x = x1 + (x2 - x1 - text_w) // 2\n",
    "        text_y = max(y1 - 10, text_h + 10)  # ettei mene kuvan ulkopuolelle\n",
    "        \n",
    "        # PiirrÃ¤ laatikko + teksti\n",
    "        cv2.rectangle(yolo_img, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "        cv2.putText(yolo_img, label, (text_x, text_y), font, font_scale, (0, 255, 255), thickness)\n",
    "\n",
    "\n",
    "        # DenseNet\n",
    "        crop = densenet_img[y1:y2, x1:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "        pil_img = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "        input_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = densenet_model(input_tensor)\n",
    "            pred_cls = output.argmax(dim=1).item()\n",
    "            dn_conf = torch.softmax(output, dim=1)[0][pred_cls].item()\n",
    "\n",
    "        dn_label = f\"{class_names[pred_cls]} ({dn_conf*100:.1f}%)\"\n",
    "        cv2.rectangle(densenet_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(densenet_img, dn_label, (text_x, text_y), font, font_scale, (0, 255, 0), thickness)\n",
    "\n",
    "\n",
    "        # Hybrid: YOLO if conf >= 0.75 else DenseNet\n",
    "        if yolo_conf >= 0.75:\n",
    "            final_cls = yolo_cls\n",
    "            final_conf = yolo_conf\n",
    "            source = \"YOLO\"\n",
    "            color = (0, 255, 255)\n",
    "        else:\n",
    "            final_cls = pred_cls\n",
    "            final_conf = dn_conf\n",
    "            source = \"DenseNet\"\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "        label = f\"{class_names[final_cls]} ({final_conf*100:.1f}%) [{source}]\"\n",
    "        cv2.rectangle(hybrid_img, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(hybrid_img, label, (text_x, text_y), font, font_scale, color, thickness)\n",
    "\n",
    "    # NÃ¤ytetÃ¤Ã¤n kolme kuvaa rinnakkain\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(yolo_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"YOLO-luokitus\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(densenet_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"DenseNet-luokitus\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cv2.cvtColor(hybrid_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Hybridiluokitus\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #class_names = [\"Betoni\", \"Ei materiala\", \"Materiaali ei tiedossa\", \"Muovi\", \"TerÃ¤s\"]\n",
    "\n",
    "    # Tulosta luokkien selitykset (esim. 0 = Betoni jne)\n",
    "    print(\"\\nðŸ“˜ Luokkakoodien selitykset:\")\n",
    "    for idx, name in enumerate(class_names):\n",
    "        print(f\"{idx} = {name}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Haetaan yksi tietty kuva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kutsu\n",
    "show_yolo_vs_densenet(\"datasets/materials/images/validation/176137_1.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Kutsutaan random kolme kuvaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "\n",
    "# Kaikki validointikuvat\n",
    "all_images = glob.glob(\"datasets/materials/images/validation/*.jpg\") + \\\n",
    "             glob.glob(\"datasets/materials/images/validation/*.png\")\n",
    "\n",
    "# Poistetaan jo kÃ¤ytetyt kuvat\n",
    "used_images = [\n",
    "    \"datasets/materials/images/validation/174114_2.jpg\"\n",
    "]\n",
    "remaining_images = list(set(all_images) - set(used_images))\n",
    "\n",
    "# Arvotaan 3 satunnaista kuvaa\n",
    "random_images = random.sample(remaining_images, 3)\n",
    "\n",
    "# Ajetaan funktio satunnaisille kuville\n",
    "for path in random_images:\n",
    "    show_yolo_vs_densenet(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
